% --- Template for thesis / report with tktltiki2 class ---
% 
% last updated 2013/02/15 for tkltiki2 v1.02

\documentclass[english]{tktltiki2}

% tktltiki2 automatically loads babel, so you can simply
% give the language parameter (e.g. finnish, swedish, english, british) as
% a parameter for the class: \documentclass[finnish]{tktltiki2}.
% The information on title and abstract is generated automatically depending on
% the language, see below if you need to change any of these manually.
% 
% Class options:
% - grading                 -- Print labels for grading information on the front page.
% - disablelastpagecounter  -- Disables the automatic generation of page number information
%                              in the abstract. See also \numberofpagesinformation{} command below.
%
% The class also respects the following options of article class:
%   10pt, 11pt, 12pt, final, draft, oneside, twoside,
%   openright, openany, onecolumn, twocolumn, leqno, fleqn
%
% The default font size is 11pt. The paper size used is A4, other sizes are not supported.
%
% rubber: module pdftex

% --- General packages ---

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{microtype}
\usepackage{amsfonts,amsmath,amssymb,amsthm,booktabs,color,enumitem,graphicx}
\usepackage[pdftex,hidelinks]{hyperref}
\usepackage{verbatim}

% Automatically set the PDF metadata fields
\makeatletter
\AtBeginDocument{\hypersetup{pdftitle = {\@title}, pdfauthor = {\@author}}}
\makeatother

% --- Language-related settings ---
%
% these should be modified according to your language

% babelbib for non-english bibliography using bibtex
\usepackage[fixlanguage]{babelbib}

% add bibliography to the table of contents
\usepackage[nottoc]{tocbibind}

% --- Theorem environment definitions ---

\newtheorem{thm}{Theorem}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{cor}[thm]{Corollary}

\theoremstyle{definition}
\newtheorem{definition}[thm]{Definition}

\theoremstyle{remark}
\newtheorem*{remark}{Remark}


% --- tktltiki2 options ---
%
% The following commands define the information used to generate title and
% abstract pages. The following entries should be always specified:

\title{Extending the “Development Pipeline” Towards Continuous Deployment and Continuous Experimentation: A Case Study in the B2B Domain}
\author{Olli Rissanen}
\date{\today}
\level{Master's thesis}
\abstract{Currently more and more software companies are moving to lean practices, which often include shorter delivery cycles and thus shorter feedback loops. However, to achieve continuous customer feedback and to eliminate work that doesn't generate value, even shorter cycles are required. In continuous deployment the software functionality is deployed continuously at customer environment. This process includes both automated builds and automated testing, but also automated deployment. Automating the whole process minimizes the time required for implementing new features in software, and allows for faster customer feedback. However, adopting continuous deployment doesn't necessarily mean that more value is created for the customer. While continuous deployment attempts to deliver an idea to users as fast as possible, continuous experimentation instead attempts to validate that it is, in fact, a good idea. In a state of continuous experimentation, the entire R\&D process is guided by controlled experiments and feedback. In it's core continuous experimentation consists of a design-execute-analyse loop, where hypotheses are selected based on business goals and strategies, experiments are executed with partial implementations and data collection tools and finally the results are analyzed to validate the hypothesis. In this paper we're .. \\\newline ACM Computing Classification System (CCS): \newline \textbf{General and reference $\rightarrow$ Experimentation} \newline \textbf{TODO: add rest}}

% The following can be used to specify keywords and classification of the paper:

\keywords{Continuous delivery, Continuous experimentation, Development pipeline}

%\classification{General and reference → Experimentation}
% classification according to ACM Computing Classification System (http://www.acm.org/about/class/)
% This is probably mostly relevant for computer scientists
% uncomment the following; contents of \classification will be printed under the abstract with a title
% "ACM Computing Classification System (CCS):"
% \classification{}

% If the automatic page number counting is not working as desired in your case,
% uncomment the following to manually set the number of pages displayed in the abstract page:
%
% \numberofpagesinformation{16 pages + 10 appendix pages}
%
% If you are not a computer scientist, you will want to uncomment the following by hand and specify
% your department, faculty and subject by hand:
%
\faculty{Faculty of Science}
\department{Department of Computer Science}
\subject{Computer Science}
%
% If you are not from the University of Helsinki, then you will most likely want to set these also:
%
\university{University of Helsinki}
% \universitylong{HELSINGIN YLIOPISTO --- HELSINGFORS UNIVERSITET --- UNIVERSITY OF HELSINKI} % displayed on the top of the abstract page
\city{Helsinki}
%


\begin{document}

% --- Front matter ---

\frontmatter      % roman page numbering for front matter

\maketitle        % title page
\makeabstract     % abstract page

\tableofcontents  % table of contents

% --- Main matter ---

\newpage

It’s hard to argue that Tiger Woods is pretty darn good at what he does. But even he is not perfect. Imagine if
he were allowed to hit four balls each time and then choose the shot that worked the best. Scary good.
-- Michael Egan, Sr. Director, Content Solutions, Yahoo (Egan, 2007)

\mainmatter       % clear page, start arabic page numbering



%case study
% Relate the theory to a practical situation; for example, apply the ideas 
%and knowledge discussed in the coursework to the practical situation 
%at hand in the case study. 
 
% Identify the problems 
% Select the major problems in the case 
% Suggest solutions to these major problems 
% Recommend the best solution to be implemented 
% Detail how this solution should be implemented

\section{Introduction} %Motivation
Currently more and more software companies are moving to lean practices, which include short delivery cycles and thus shorter feedback loops. 

The requirement of developing value fast have lead to the evolution of a new software development model \cite{bosch2012building}. The modeĺ is based on three principles: evolving  the software by frequently deploying new versions, using customers and customer data throughout the development process and testing new ideas with the customers to drive the development process and increase customer satisfaction.



Lean software development, which was inspired by the Toyota Production System \cite{}, is a development approach attempting to eliminate unnecessary work and to create value for the customer. The approach consists of seven principles: eliminate waste, build quality in, deliver fast, optimise the whole, create knowledge, defer commitment and respect people. 

TODO: Connect this thesis with the Lean Startup Build-Measure-Learn cycle

IEEE divides the quality of a software component into two components: how well the software meets software requirements specifications, and how useful the software is to the end user.

CMMI 5th stage 

A way to shorten the delivery cycles and to automate the delivery process is continuous deployment. It is an extension to continuous integration, where the delivery process is often entirely automated, and software functionality is deployed frequently to customer environment. While continuous integration defines a process where the work is automatically built, tested and frequently integrated to mainline \cite{fowler2006continuous}, often multiple times a day, continuous deployment adds automated acceptance testing and deployment. Continuous deployment therefore attempts to deliver an idea to users as fast as possible by automating the deployment process.

Define continuous experimentation principles here

In the context of this thesis, Continuous Experimentation refers to a development model following these principles: TODO: improve this
\begin{itemize}
\item  Data driven decisions
\item  Link product development and business aspect
\item  React to customers present needs
\item  Turn hypotheses into facts
\item  Steer development process
\end{itemize}

%While continuous experimentation is a term loosely defined by McKinley, it poses resemblance to multiple development models, such as the Innovation Experiment System \cite{bosch2012building}. The key principles in these development models are data-driven decisions, linking product development and business aspect, reacting to customers present needs, turning hypotheses into facts, failing fast and steering the development process. 

Bosch et al. introduce an innovation experiment system, where the development process consists of frequently deploying new versions, using customers and customer usaged data in the development process and finally by focusing on innovation and testing ideas with customers to drive customer satisfaction and revenue growth \cite{bosch2012building}. "First, it frequently deploys new versions focusing on continuously evolving the embedded software in short cycles of 2-4 weeks" \cite{eklund2012architecture}.

Continuous experimentation attempts to validate that an idea is, in fact, a good idea. In continuous experimentation the organisation runs controlled experiments to guide the R\&D process. The development cycle in continuous experimentation resembles the build-measure-learn cycle of lean startup \cite{ries2011lean}. The process in continuous experimentation is to first form a hypothesis based on a business goals and customer "pains" \cite{bosch2012building}. After the hypothesis has been formed, quantitative metrics to measure the hypothesis must be decided. After this a minimum viable product can be developed and deployed, while collecting the required data. Finally, the data is analyzed to attempt to validate the hypothesis.

%Data driven development
%Iteration of ideas in a controlled way
%Fail fast

\begin{figure}[h]
	\centering
	\includegraphics[width=3.5in]{stairway.png}
	\caption{Organization evolution path \cite{olsson2012climbing}.}
\end{figure}

In this thesis we conduct a case study to analyse the adoption of continuous deployment and continuous experimentation in B2B domain. The case study consists of a literature review on applications of these practices, an interview of key members in the case company and analysis of the results. 

The purpose of this thesis is to

The main research questions are as follows.
\begin{itemize}
\item  \textbf{RQ 1: What is the Minimum Viable Process of continuous experimentation? How can the process be simplified without losing the benefits?}
\item  \textbf{RQ 2: What are the differences in continuous experimentation and continuous delivery in B2B as compared to B2C?}
\item  \textbf{RQ 3: Why would continuous experimentation benefit the case company? What are the problems and strengths of the current development process?}
\item  \textbf{RQ 4: How to collect usage data and customer feedback in B2B domain, where user amounts can be very low?}
\item  \textbf{RQ 5: How should continuous experimentation be implemented as a development process?}
\end{itemize}

The research approach is %approach

This thesis is organized as follows. Chapter II ..
%Structure:
%
%#1
%Background information - case study context - results - limitations - summary, future work
%#2
%Related work - experimental setup - results - summary
%-GOAL OF THE THESIS
%-motivation
%-research question
%-approach
%>analyze state of the practice
%>specify problem and goals 
%>analyze state of the art
%>state hypotheses
%>derive solution idea

\section{Continuous delivery and continuous experimentation}
%Agile
Agile software development emerged from the iterative software development methods, with early implementations being development in the 1990's \cite{dybaa2008empirical}. The general principles of agile software development are breaking the development to short iterations, maintaining a short feedback loop with the customer by having a customer representative, valuing working software over documentation and responding to change.

%Agile implementations
Many agile models, such as Scrum \cite{schwaber2002gile}, Extreme Programming \cite{beck2000extreme} and Feature-Driven Development \cite{palmer2001practical} further defined their own strategies based on the agile principles. Scrum, for example, defines a framework for managing product development, without much focus on technical tools. Extreme Programming, on the other hand, includes many technical features, such as always programming in pairs, doing extensive code review and unit testing all code.

%Lean manufacturing & LSD
Lean manufacturing, derived from the Toyota Production System \cite{ono1988toyota}, is a streamlined production philosophy that aims to identify the expenditure of resources not used in creating value for the end customer, and eliminate these activities. Lean software development \cite{poppendieck2003lean} has been developed based on the same idea. The purpose of lean software development is to eliminating waste, or anything that doesn't bring value to the customer, and to pursuit perfection through smoothing the development flow. The principles in lean software development are eliminate waste, amplify learning, decide as late as possible, deliver as fast as possible, engage everyone, build quality in and see the whole. 

%Lean startup
Lean startup \cite{ries2011lean} is a business and product development method with focus on business-hypothesis-driven experimentation and iterative product releases. A primary purpose of lean startup is to assess the specific demands of consumers and to fulfill those demands with the least possible resources. This is achieveved by using a Build-Measure-Learn-loop, which is used to learn the customers actual needs and consecutively to steer business and product strategies to the correct direction. The tight customer feedback loop ensures that the product development doesn't include features and services not wanted by the customer. 

TODO:
-Stairway to heaven
-Innovation experiment system

\subsection{Continuous deployment}
%what is it
Continuous deployment is an extension to continuous integration, where the software functionality is deployed frequently at customer environment. While continuous integration defines a process where the work is automatically built, tested and frequently integrated to mainline \cite{fowler2006continuous}, often multiple times a day, continuous deployment adds automated acceptance testing and deployment. The purpose of continuous deployment is that as the deployment process is completely automated, it reduces human error, documents required for the build and increases confidence that the build works \cite{cdbook}. 

%release cycles
In an agile process software release is done in periodic intervals \cite{cockburn2002agile}. Compared to waterfall model it introduces multiple releases throughout the development. Continuous deployment, on the other hand, attemps to keep the software ready for release at all times during development process \cite{cdbook}. Instead of stopping the development process and creating a build as in an agile process, the software is continuously deployed to customer environment. This doesn't mean that the development cycles in continuous deployment are shorter, but that the development is done in a way that makes the software always ready for release.
\begin{figure}[h]
	\centering
	\includegraphics[width=3.5in]{rtvd.jpg}
	\caption{Continuous integration, delivery and deployment.}
	\label{fig1}
\end{figure}
%delivery vs deployment
Continuous delivery differs from continuous deployment. Refer to Fig. \ref{fig1} for a visual representation of differences in continuous integration, delivery and deployment. Both include automated deployment to a staging environment. Continuous deployment includes deployment to a production environment, while in continuous delivery the deployment to a production environment is done manually. The purpose of continuous delivery is to prove that every build is proven deployable \cite{cdbook}. While it necessarily doesn't mean that teams release often, keeping the software in a state where a release can be made instantly is often seen beneficial.

%Barriers in CI->CD transition: stairway
Holmström Olsson et al. have researched the transition phase from continuous integration to continuous delivery, and have identified barriers that companies need to overcome to achieve the transition \cite{olsson2012climbing}. One of such barrier is the custom configuration at customer sites. Maintaining customized solutions and local configurations alonside the standard configurations creates issues. The second barrier is the internal verification loop, that has to be shortened not only to develop features faster but also to deploy fast. Finally, the lack of transparency and getting an overview of the status of development projects is seen as a barrier.
Olsson et al. state that in order to shorten the internal verification loop, different parts in the organization should also be involved, especially the product management as they are the interface to the customer. Olsson et al. also note that finding a pro-active lead customer is also essential to explore and form aa new engagement model.

\subsubsection{Deployment pipeline}
An essential part of continuous deployment is the deployment pipeline, which is an automated implementation of an application's build, deploy, test and release process \cite{cdbook}. A deployment pipeline can be loosely defined as a consecutively executed set of validations that a software has to pass such before it can be released. Common components of the deployment pipeline are a version control system and an automated test suite.

Humble and Farley define the deployment pipeline as a set of stages, which cover the path from a committed change to a build \cite{cdbook}. Refer to Fig. \ref{fig2} for a graphical representation of a basic deployment pipeline. The commit stage compiles the build and runs code analysis, while acceptance stage runs an automated test suite that asserts the build works at both functional and nonfunctional level. From there on, builds to different environments can be deployed either automatically or by a push of a button.

Humble et al. define four principles that should be followed when attempting to automate the deployment process \cite{humble2006deployment}. The first principle states that "Each build stage should deliver working software". As software often consists of different modules with dependencies to other modules, a change to a module could trigger builds of the related modules as well. Humble et al. argue that it is better to keep builds separate so that each discrete module could be built individually. The reason is that triggering other builds can be inefficient, and information can be lost in the process. The information loss is due to the fact that connection between the initial build and later builds is lost, or at least causes a lot of unnecessary work spent in tracing the triggering build. 

The second principle states that "Deploy the same artifacts in every environment". This creates a constraint that the configuration files must be kept separate, as different environments often have different configurations. Humble et al. state that a common anti-pattern is to aim for 'ultimate configurability', and instead the simplest configuration system that handles the cases should be implemented.
\begin{figure}[h]
	\centering
	\includegraphics[width=3.5in]{pipeline.jpg}
	\caption{A basic deployment pipeline \cite{cdbook}.}
	\label{fig2}
\end{figure}
Another principle, which is the main element of continuous deployment, is to "Automate testing and deployment". Humble et al. argue that the application testing should be separated out, such that stages are formed out of different types of tests. This means that the process can be aborted if a single stage fails. They also state that all states of deployment should be automated, including deploying binaries, configuring message queues, loading databases and related deployment tasks. Humble et al. mention that it might be necessary to split the application environment into $slices$, where each slice contains a single instance of the application with predetermined set of resources, such as ports and directories. $Slices$ make it possible to replicate an application multiple times in an environment, to keep distinct version running simultaniously. Finally, the environment can be smoke tested to test the environments capabilities and status.

The last principle states "Evolve your production line along with the application it assembles". Humble et al. state that attempting to build a full production line before writing any code doesn't deliver any value, so the production line should be built and modified as the application evolves. 

\subsubsection{Impact on development model}

A picture of the typical development process in continuous deployment is shown in Fig. \ref{fig3}. After the team pushes a change to the version control system, the project is automatically built and tests are triggered stage by stage. If a test stage fails, feedback is given and the deployment process effectively cancelled. In a continuous delivery process, the last stages are approved and activated manually, but in a continuous deployment process the last stages are triggered automatically as well.

\begin{figure}[h]
	\centering
	\includegraphics[width=3.5in]{developmentprocess.jpg}
	\caption{Components of the development process \cite{cdbook}.}
	\label{fig3}
\end{figure}

\subsection{Continuous experimentation}
-for a method: what, how, when, who

%Continuous experimentation term
Continuous experimentation is a term created by Dane McKinley, a Principal Engineer at Etsy \cite{mcfunley}. McKinley defines the key aspects of continuous experimentation as making small, measurable changes, staying honest and preventing the developers from breaking things. With staying honest, McKinley implies that the product releases are tracked and measured, so that it's possible to tell whether things went worse or better. McKinley also states that design and product process must change to accomodate experimentation, and that experimenting should be done with minimal version of the idea. When experimentations are implemented and measured, counterintuitive results will be found, and planning to be wrong should be considered \cite{mcfunley}. 
%Prefer incremental redesigns. 

%Continuous experimentation intro
While continuous experimentation is only loosely defined by McKinley, it poses resemblance to multiple development models, such as the Innovation Experiment System \cite{bosch2012building}. The key principles in these development models are data-driven decisions, linking product development and business aspect, reacting to customers present needs, turning hypotheses into facts, failing fast and steering the development process. Fagerholm et al. define that a suitable experimentation system must be able to release minimum viable products or features with suitable instrumentation for data collection, design and manage experiment plans, link experiment results with a product roadmap and manage a flexible business strategy \cite{fagerholm2014building}. The Build-Measure-Loop of Lean Startup is similar in the sense that controlled experiments drive the development.

%Lean startup
In Lean startup methodology \cite{ries2011lean} experiments consist of Build-Measure-Learn cycles, and are tightly connected to visions and the business strategy. The purpose of a Build-Measure-Learn cycle is to turn ideas into products, measure how customers respond to the product and then to either pivot or persevere the chosen strategy. The cycle starts with forming a hypothesis and building a minimum viable product (MVP) with tools for data collection. Once the MVP has been created, the data is analyzed and measured in order to validate the hypothesis. To persevere with a chosen strategy means that the experiment proved the hypothesis correct, and the full product or feature can is implemented. However, if the experiment proved the hypothesis wrong, the strategy is changed based on the implications of a false hypothesis.

%Evolution path
Holmström Olsson et al. have researched the typical evolution path of companies \cite{olsson2012climbing}. The final stage of the evolution phase is when development is driven by the real-time customer usage of software. Defined as "R&D as an 'experiment system'", the entire R&D system acts based on real-time customer feedback and development is seen as addressing to customers present needs. At the same time deployment of software is seen as a "starting point for 'tuning' of functionality rather than delivery of the final product". While the evolution from continuous deployment to innovation system wasn't explored, Olsson et al. anticipate that the key actions required are the automatical data collection components and capability to effectively use the collected data.

-Connect CE, IES, Microsoft stuff, Lean startup stuff

%In the context of this thesis, Continuous Experimentation refers to a development model following these principles: TODO: improve this
%\begin{itemize}
%\item  \textbf{Data driven decisions}
%\item  \textbf{Link product development and business aspect}
%\item  \textbf{Reacting to customers present needs}
%\item  \textbf{Turning hypotheses into facts}
%\item  \textbf{Steering development process}
%\end{itemize}

A model of continuous experimentation has been created by Fagerholm et al. \cite{fagerholm2014building}. 

%Experiment
An experiment is essentially a procedure to confirm the validity of a hypothesis. In software engineering context, experiments attempt to answer questions such as which features are necessary for a product to succeed, what should be done next and which customer opinions should be listened to. According to Jan Bosch, "The faster the organization learns about the customer and the real world operation of the system, the more value it will provide" \cite{bosch2012building}. Most organizations have many ideas, but the return-on-investment for many may be unclear and the evaluation itself may be expensive \cite{kohavi2007practical}. 

%Continuous deployment - continuous experimentation integration
Continuous deployment attempts to deliver an idea to users as fast as possible. Continuous experimentation instead attempts to validate that it is, in fact, a good idea. In continuous experimentation the organisation runs controlled experiments to guide the R\&D process. The development cycle in continuous experimentation resembles the build-measure-learn cycle of lean startup. The process in continuous experimentation is to first form a hypothesis based on a business goals and customer "pains" \cite{bosch2012building}. After the hypothesis has been formed, quantitative metrics to measure the hypothesis must be decided. After this a minimum viable product can be developed and deployed, while collecting the required data. Finally, the data is analyzed to attempt to validate the hypothesis.

%innovation experiment system
Jan Bosch has widely studied continuous experimentation, or innovation experiment systems, as a basis for development. The primary issue he found is that "experimentation in online software is often limited to optimizing narrow aspects of the front-end of the website through A/B testing and inconnected, software-intensive systems experimentation, if applied at all, is ad-hoc and not systematically applied" \cite{bosch2012building}. The author realized that for different development stages, different techniques to implement experiments and collect customer feedback exist. Bosch also introduces a case study in which a company, Intuit, adopted continuous experimentation and has increased both the performance of the product and customer satisfaction.

\cite{eklund2012architecture}
Applied the continuous experimentation research to embedded software.
"Improvement occurs in individual software parts, but the underlying design concept remain mostly unchanged [3]"
"The experiment infrastructure allows developers to deploy new software and collect data how it behaves in areal-world settings being used by actual users. The infrastructure support deployment of software experiments and collection of data over-the-air on a scale comparable to the entire customer base". 
"The infrastructure supports with automated randomisation and factorial designs [6] sufficient to draw statistical conclusions from the experimental scenarios."
"The experiment manager architecture, seen in Figure 3, supports the deployment of multiple experimental software parts to the same device and autonomously controls when to run which experiment, even allowing for local A/B-testing. Measurements and analysis is done on-board in real-time. The experiment scenario to be answered is implemented on the embedded device (i.e. how long does it take to . . . )"
TODO: picture here

\subsubsection{Experimentation planning}

\subsubsection{Experimentation stages and scopes}
Fig. \ref{fig4} introduces different stages and scopes for experimentation. For each stage and scope combination, an example technique to collect product performance data is shown. As startups often start new products and older companies instead develop new features, experiments must be applied in the correct context. Bosch states that for a new product deployment, putting a minimal viable product as rapidly as possible in the hands of customers is essential \cite{bosch2012building}. After the customers can use the product, it is often not yet monetizable but is still of value to the customer. Finally, the product is commercially deployed and collecting feedback is required to direct R\&D investments to most valuable features.
\begin{figure}[h]
	\centering
	\includegraphics[width=3.5in]{scopes.jpg}
	\caption{Scopes for experimentation \cite{bosch2012building}.}
	\label{fig4}
\end{figure}

\subsubsection{Components in continuous experimentation}
Kohavi et al. investigate the practical implementations of controlled experiments on the web \cite{kohavi2007practical}, and state that the implementation of an experiment involves two components. The first component is a randomization algorithm, which is used to map users to different variants of the product in question. The second component is an assignment method which, based on the output of the randomization algorithm, determines the contents that each user are shown. The observations then need to be collected, aggregated and analyzed to validate a hypothesis. Kohavi et al. also state that most existing data collection systems are not designed for the statistical analyses that are required to correctly analyze the results of a controlled experiment.

The components introduced by Kohavi et al. are aimed primarily for A/B testing on websites. Three ways to implement the assignment methods are shown. The first one is traffic splitting, which directs users to different fleet of servers. An alternative methods is server-side selection, in which API calls invoke the randomization algorithm and branch the logic based on the return value. Last alternative is a client-side selection, in which the front-end system dynamically modifies the page to change the contents. Kohavi et al. state that the client-side selection is easier to implement, but it severely limits the features that may be subject to experimentation. Experiments on back-end are nearly impossible to implement in such manner.

\subsubsubsection{Data collection}
"Active customer feedback is concerned with surveys and other mechanisms where the customer is aware that he or she is providing feedback. Passive feedback and usage data is collected while the customer is using the system. Examples include the amount of time a user spends using a feature, the relative frequency of feature selections, the path that the user takes through the product functionality, etc. The low cost and ease of data collection leads to the next major difference between IES-based and traditional software." \cite{bosch2012building}


To collect, aggregate and analyze the observations, raw data has to be recorded. According to Kohavi et al., some raw data could be for example page views, clicks, revenue, render time and customer-feedback selections \cite{kohavi2007practical}. The data should also be annotated to an identifier, such that conclusions can be made from it. Kohavi et al. present three different ways for collecting raw data. The first solution is to simply use an existing data collection tool, such as Webmetrics. However, most data collection systems aren't designed for statistical analyses, and the data might have to be manually extracted to an analysis environment. A different approach is local data collection, in which a website records data in a local database or log files. The problem with local data collection is that each additional source of data, such as the back-end, increases the complexity of the data recording infrastructure. The last model is a service-based collection, in which service calls to a logging service are placed in multiple places. This centralizes all observation data, and makes it easy to combine both back-end and front-end logging.  

\subsubsubsection{Data analysis}
To analyze the raw data, it must first be converted into metrics which can then be compared between the variants in a given experiment. An arbitrary amount of statistical tests can then be run on the data with analytics tools in order to determine statistical significance. 

\subsubsection{Roles in continuous experimentation}
Fagerholm et al. define five different roles in continuous experimentation: Business Analyst, Product Owner, Data Analyst, Software Developer and Quality Assurance \cite{fagerholm2014building}. The business analyst along with the product owner are responsible for creating and updating the strategic roadmap, which is the basis of the hypotheses. The basis for decisions are the existing experimental plans and results stored in a database. A data analyst is used to analyze the existing experiments and results and to create assumptions from the roadmap. The analyst is also responsible for the design and execution of experiments. The data analyst is in tight collaboration with the software developer and quality assurance, who are reponsible for the development of MVPs and MVFs. The software designers create the necessary instrumentations used to collect the data required by the analyst.

%question: what if there are no existing experimental plans, and this is the first experiment? how should the roadmap be created?

\begin{figure}[h]
	\centering
	\includegraphics[width=5in]{infra.jpg}
	\caption{Continuous experimentation infrastructure \cite{fagerholm2014building}.}
	\label{fig4}
\end{figure}

%http://www.janbosch.com/Jan_Bosch/Innovation_Experiment_Systems.html
\subsection{Continuous deployment and continuous experimentation collaboration}
As the experiments are run in a regular fashion, integrating experiments to the deployment pipeline should be considered. This requires changing the development process in such fashion that functionality is developed based on some actual data. The components required to support continuous experimentation include tools to assign users to treatment and control groups, tools for data logging and storing, and analytics tool for conducting statistical analyses.

\subsection{Challenges regarding continuous delivery}
-Technical implementation
-Education on the subject
-Active participation of employees

\subsection{Challenges regarding continuous experimentation}
"Experimentation in practice is often limited to optimizing narrow aspecs of the front-end through A/B testing, and is not systematically applied" \cite{bosch2012building} 

"Collecting customer or performance data early in the innovation process requires changes to the R&D processes, as customers need to be involved much earlier and deeper in the process. This also requires architectural changes of the product and platform to determine customer preference and interest." \cite{bosch2012building}

"A final aspect is the avoidance of versioning of software. Traditionally, for many companies, every customer would ultimately have a unique configuration of the product with different versions of components making up the system. This adds a whole new layer of complexity to the already costly process of deploying new versions. In an IES environment, there is only one version: the currently deployed one. All other versions have been retired and play no role." \cite{bosch2012building}

"Innovation in large organization is often characterized by an enormous imbalance between the number of ideas that, informally or formally, exist in the organization and the number of concepts that are in fact tested with customers." \cite{bosch2012building}

"Traditional metrics such as the Net Promoter Score[Reichheld, F.F.: The One Number You Need to Grow] have been used for the last decade or more, but often fail to provide timely feedback during the development process as these are backward looking and focus on the entire product." \cite{bosch2012building}

"Most organizations have many ideas, but the return-on-investment (ROI) for many may be unclear and the evaluation itself may be expensive." \cite{kohavi2007practical}

-Randomization algorithm and assignment method, data collection, storage, analysis \cite{kohavi2007practical}

Pitfalls:
\begin{figure}[h]
	\centering
	\includegraphics[width=3.5in]{pitfalls.jpg}
	\caption{Pitfalls to avoid when running controlled experiments \cite{crook2009seven}.}
\end{figure}

-Roles
-Environment
-Deployment

\section{Case study as a research method}

\subsection{Case study}
Case study is a way to collect data through observation and to test theories in an unmodified setting \cite{zelkowitz1998experimental}. The case in a case study is the situation, individual, group or organization that the researchers are interested in \cite{robson2002real}. Kitchenham et al. found case studies important for industrial evaluation of software engineering methods and tools \cite{kitchenham1995case}. Runeson and Höst define it as a suitable research method for software engineering, since it studies contemporary phenomena in its natural context \cite{runeson2009guidelines}. It might not be possible to generate causal relationships from case studies as compared to controlled experiments. However, they provide a deeper understanding of the unit under study \cite{runeson2009guidelines}. An opposite type of research would be a formal experiment, with a narrow focus and control on variables. 

Case studies can serve different purposes. Robson defines four purposes as Exploratory, Descriptive, Explanatory and Improving \cite{robson2002real}. In an exploratory case study, the purpose is to seek new insights, find out what is happening and generate ideas and hypotheses for new research. Descriptive case study attempts to portray a situation or a phenomenom. Explanatory case study attempts to seek and explanation to a problem or situation, mostly in a causal relationship. An improving case study tries to improve an aspect of the studied phenomenom.  

Runeson and Höst define the case study structure in five steps \cite{runeson2009guidelines}. First the case study is designed: objectives are defined and the study is planned. Then procedures and protocols for data collection are defined. Then the evidence is collected by executing the data collection on the studied case. The collected data is then analysed, and finally the results are reported.

Triangulation is a way to increase the reliability and validity of the findings. Triangulation means using different data collection methods or angles, and providing a wider picture of the case. Triangulation is especially important for qualitative data, but can also be used for quantitative data to compensate for measurement or modeling errors \cite{runeson2009guidelines}. Stake defines four ways to apply triangulation: Data triangulation, Observer triangulation, Methodological triangulation and Theory triangulation \cite{stake1995art}. In data triangulation, multiple data sources are used, or the data is collected at different occasions. In observer triangulation more than one observer is used in the study. In methodological triangulation different types of data collection methods are combined, such as qualitative and quantitative methods. In theory triangulation alternative theories or viewpoints are used.

Data collection in case studies tend to lean towards qualitative data that provides a richer and deeper view as compared to quantitative data \cite{runeson2009guidelines}. As a data collection method, semi-structured interviews are common in case studies \cite{runeson2009guidelines}. However, generalizing the results of a case study is often a subject of internal validity \cite{kitchenham2002preliminary}. It is especially important in a case study to address reliability and validity of the findings. Even with good faith and intention, biased and selective accounts can emerge \cite{robson2002real}. 

\subsection{Qualitative research}
Qualitative research attempts to answer to questions "Why?"" and "How?" instead of "What?", "Where?" and "When?" as compared to quantitative research. The most common way to collect qualitative data is via an interview. Seaman defines interviews as a way to collect historical data, opinions and impressions about something \cite{seaman1999qualitative}. The interview can be either structured, unstructured or semi-structured. In a structured interview the interviewer asks all of the questions, and the objectives are very specificed. The focus of a structured interview is to find relations between constructs, and the objective is descriptive and explanatory \cite{runeson2009guidelines}. In an unstructured interview the topic is broadly defined, and questions are asked also by the interviewee. In an unstructured interview open-ended questions are typical, and unforeseen types of information can be gained. The focus of an unstructured interview is on how the interviewee qualitatively experience the phenomenom, and the objective is exploratory \cite{runeson2009guidelines}. A semi-structure interview is a mixture of both open-ended and specific questions. Semi-structured interviews focus on how individuals qualitatively and quantitatively experience a phenomenom, and the objective is both descriptive and explanatory \cite{runeson2009guidelines}.

Qualitative data analysis \cite{robson2002real}

Seaman has explored qualitative research in software engineering context, and he defines different ways to analyse qualitative data. \cite{seaman1999qualitative} 
-Coding, extracting values for quantitative variables from qualitative data
-Coding subjective data, select reference points for views, evaluate relability
-Generation of Theory (GoT), extract from a set of field notes a statement or proposition supported in multiple ways by the data - – for use as hypotheses
-GoT cross-case analysis: data divided into “cases”: two groups based on some attribute and examine similarities and differences (devs / management?)
-Confirmation of Theory: target: building up “weight of evidence"; triangulation; anomalies in the data
-qualitative data is richer than quantitative data. use of qualitative methods increases
– amount of information
– diversity of information
– confidence in results

The basic objective of data analysis is to form conclusions and theories from the data based on a chain of evidence. Qualitative data analysis can be divided into two different parts, hypothesis generating techniques and hypothesis confirmation techniques \cite{runeson2009guidelines}. Both of these techniques can be exploratory and explanatory case studies \cite{runeson2009guidelines}.  

%Quasi-statistical approaches, Template approaches, Editing approaches, Immersion approaches 
Robson introduces common features of qualitative data analysis in a sequential list \cite{robson2002real}. The first step is to code the initial set of data. Then, comments and reflections (referred to as 'memos') are added. After this the data is processed, similar phrases, patterns, themes, relationships and differences between sub-groups are identified. These identified patterns are then used to focus the next data collection phase. Gradually a set of generalizations are formed, that cover the consistencies discerned in the data. These generalizations are then linked to a formalized body of knowledge in the form of constructs or theories. 

In the sequential list, hypotheses are identified after the data has been coded. The hypotheses are then used to guide the following data collection process in an iterative approach. During the iterations, some generalizations can be formed, which eventually form a formalized body of knowledge as a final result.

Hypothesis generating techniques are for example "constant comparison method" and "cross-case analysis" \cite{seaman1999qualitative}. In the constant-comparison method the field notes are coded, text pieces are grouped into patterns and propositions that are strongly supported by the data are made. The propositions are then validated against any new data. In the cross-case analysis method data is divided into cases, such as two groups based on the same attribute. Pairs of cases are then compared to determine validations and similarities. 

The data analysis can be conducted with multiple different approaches, with each having a varying degree of formalism. Robson lists four such approaches, from least formal to most formal: Immersion approaches, Editing approaches, Template approaches and Quasi-statistical approaches \cite{robson2002real}. Immersion approaches are the least format, relying mostly on the interpretive skills of the researcher and having a low level of structure. Editing approaches include the usage of some codes which the researcher decides based on findings during the analysis. Template approaches, also known as template analysis, use priori codes to develop a coding template, organising the data based on themes. Quasi-statistical approach is the most formal approach, including quantitative calculations, such as word frequencies. Runeson and Höst state that editing approaches and template approaches are most suitable for software engineering case studies, as a clear chain of evidence is hard to obtain in immersion approaches, and word frequencies are hard to interpret \cite{runeson2009guidelines}. 

\subsubsection{Template analysis}

Template analysis doesn't describe a clearly defined method, but rather refers to a related group of techniques used to thematically organise and analyse textual data \cite{king2004using}. Template analysis is a relatively structured process to analyse textual data, and has mostly been used to analyse data from individual interviews \cite{king2012doing}. The key component in template analysis is the generation of a coding template, which is initially formed on the basis of a subset of the data and then applied to further data. 

King defines code as a label attached to a section of text to index it as a relating to a theme or issue in the data \cite{king2004using}. As an example, codes can be defined to identify points in the text where an interviewee mentions particular categories of presenting problems. These kind of codes can be descriptive, and require no further analysis by the researcher. However, also codes requiring more interpretation can be defined. In template analysis, a key feature is to form a hierarchical organization of codes \cite{king2004using}. This way groups of similar codes are clustered together to form higher-order codes. This way the researcher can analyse the data at different levels of specifity, with higher-order codes giving a broad view and lower-order codes a more specific view. Parallel coding, where the same text segment is categorised with two different codes, is also allowed. 

The process of template analysis is to first create an initial template based on some pre-defined codes \cite{king2004using}. Then the template is revised by working through the data systematically while identifying and coding sections of interest in the text. Based on these findings, the initial template is modified, and finally develops to its final form. Modifications can be either insertion, deletion, changing scope or changing higher-order classification \cite{king2004using}. The final template is such that no sections of text related to research questions remains uncoded. 

The template is then used in interpretation to provide an account. King lists various guidelines that can be used in the interpretation of coded data \cite{king2004using}. The first guideline is to compile a list of all codes with some indication of frequency. The distribution of codes can then help to draw attention to the aspects of data with either multiple codes or missing codes. For example, if one interview in a set of interviews is missing a certain theme, analysis for possible reasons behind that missing code can be made. However, King suggests that while patterns can be used to draw attention to certain parts of the textual data, frequencies alone cannot be to gain any meaningful information. 

Another guideline is selectivity. King states that every code cannot be interpreted to equal degree of depth, and themes most relevant to understanding the phenomena under study must be identified. Prior assumptions of the researched shouldn't limit the analysis. Yet another guideline is openness, which King describes as taking themes judged as marginal into account. Themes that aren't of direct relevance to the initial research questions shouldn't be disregarded, as they can play a useful role in adding to the background of the study. Also themes lying outside the scope of the study should be included in the analysis, if they're considered to cast light on the interpretation of central themes in the study. Finally, King explains that purely linear relationships between codes, such as hierarchical relationships with subsidiary codes next to parent codes, "may not reflect the kinds of relationships a researcher may want to depict in his or her analysis". Instead, maps, matrices and other diagrams can be used to explore and display findings, and analysis doesn't have to stop when a full linear template is produced.

Finally, an account of the interpreted data has to be presented. As with interpretation, King provides three common approaches to presentation \cite{king2004using}. First of the approaches is a set of individual case studies, followed by discussion of differences and similarities between cases. This approach gives a lot of perspective of individuals, but can be confusing if the amount of participants is large. The second approach is an account structured around the main themes identified, drawing illustrative examples from each transcript as required. King states that this is the approach that most readily provides a clear thematic discussion, but the dangers is in drifting towards generalizations and losing sights of individual experiences. The third approach is a thematic presentation of the findings, using a different individual case-study to illustrate each of the main themes. The main problem here lies in selecting the cases which represent the themes in the data as a whole. King also adds that no matter which approach is used, direct quotes from participants is essential.  
%Template TODO: http://www.hud.ac.uk/hhs/research/template-analysis/what-is-template-analysis/ 

\section{Current development process of the case company}	
%an overview of the entire process, then refining the parts that are relevant for the problems 
Steeri is a mid-sized company of 80 employees, focusing in managing and improving customer data usage. This includes CRM systems, business intelligence solutions, customer dialog and data integration. Steeri has created Customer data management (CDM) and Customer dialog (Dialog) products, which are developed by two different teams. 

These two teams develop in an agile manner, but the continuous integration process \cite{fowler2006continuous} and short feedback cycles aren't achieved yet. 

The development isn't at all distributed, and no external party affects the development process. 

\subsection{iSteer Contact backlog tool}

\subsubsection{Overview}

\subsubsection{Customer backlog}
Work items are first added to customer backlogs in iSteer Contact. In this phase they might be just initial skeletons and do not need to contain all needed information. The work items are added by product or business owners or project managers. At this phase the created backlog items are not yet visible in team backlogs in iSteer Contact. The idea is to list them in the customer backlog as early as possible and start refining the requirements collaboratively both offline and online with the help of tools such as Chatter. Chatter can be used to discuss a single story or the complete backlog.

When the backlog item is ready for the development team to start working on it, it should contain at least the following information:
A descriptive name
Specifications that explain both the technical side and the business side
Agilefant link four hour reporting

The backlog item is added to team backlog by selecting the “show in team backlog” -option.

\subsubsection{Team backlog}
Team backlog is a view to all stories assigned to one selected team. It is a tool to collect and organize stories from all customer/project backlogs without cloning details into multiple places. It’s just a view of all “in team backlog” stories that are not yet completed and are assigned to the selected team.

Completed stories related to one team can be found from the report (link in team detail page)
Team backlog items (stories) are prioritized and estimated once a week (Tuesday) and new stories will be moved to Trello when accepted by the development team.

Stories can be moved to Trello by project managers or product owners but they must be checked by team leader (Juha) who then moves them forward into the sprint backlog or prioritized list columns.

\subsection{Using Trello}

Overview
Trello is a project management application that uses Kanban to control the production chain from development to release. Kanban attempts to limit the work currently in progress by establishing an upper limit of tasks in the backlog, thus avoiding overloading of the team. Trello consists of multiple boards, each representing a project or a development team. A board consists of a list of columns, and each column consists of cards. Columns each contain a list of tasks, and cards progress from one column to the next when each task has been completed. A card is essentially a task, which is added by the Backlog Owner, and can be checked out by a developer. In Steeri, the columns used are Sprint Backlog, In Progress, Review, Ready, Verified and Done. 

Sprint Backlog
The Backlog Owner moves the cards that have the highest priority into the sprint backlog. The sprint backlog should always contain enough cards so that whenever a developer completes a task something new is available in the backlog.

In progress
The actual development work is done in this stage. The actor here is the developer. The checklist to move a card into review stage is:
·       All tasks are complete
·       Changes are pushed to a feature-specific branch
·       Unit tests are written and pass in the CI server
·       Feature is well-written and does not need refactoring
·       Pull request is created and a link is added to the comment field
·       Feature has been documented as needed
If the feature needs refactoring a task list must be created and the card moved back to In Progress column.

Review
Here other developers review the new code and deploy it to a development environment. Checklist for moving the card into ready stage is:
·       Pull request is reviewed and by at least two (2) persons
·       Pull request is merged to the development branch
·       Feature is deployed to a development environment
·       Source code quality has to be good enough!
After you have reviewed the pull request leave yourself as an assignee. The second person who reviews the pull request is responsible for cleaning all the assignees and moving the feature to Ready column.
If there is a major problem in the pull request the feature should be moved back to Sprint Backlog and the yellow “Boomerang” tag added. Person who created the pull request is responsible for implementing the necessary remarks.
If only small fixes are needed, they should be implemented within the Github pull request workflow.
The second person who has reviewed and accepted the pull request is responsible for deploying the feature to a development environment.

Ready
Here the product owner verifies the new functionality in the development environment. The card can be moved to Verified if:
·       Feature has been verified by the Product Owner in the development environment
Product owner is responsible for moving the feature to the Verified column.
If the verification for the feature fails the Product Owner should move the feature back to Sprint Backlog column with the highest priority. In addition the Product Owner should add a yellow “Boomerang” label with a comment describing the results in the feature.

Verified
Here the backlog owner collects the timestamps and trello flow data. The timestamps depicts the duration it took from a card to process through the whole chain. The data is then used to analyze which columns the card spent the longest time in, and to identify the pain spots.
Done

This column simply states that the task has been completed, and should eventually be archived. There’s currently no general validation required from the customer, as the customer projects each have a different schedule and process for builds.
Prioritized lists

The backlog owner adds tasks to prioritized lists from team backlog as soon as the tasks meet the required criterias, contain the required information and are inspected by both the stakeholders and the backlog owner.

\subsection{After Trello}
Thnergefwdqa

\cite{olsson2012climbing}

-current state at steeri
    -short summary

Be sure to specify as much of the industrial context as possible. In particular,
clearly deﬁne the entities, attributes, and measures that are capturing the contextual information.

\section{Research study}

\subsection{Objective} %what to achieve?

The study is an exploratory case study, which aims to explore how continuous deployment and continuous experimentation can be integrated to the development process of the company in question. The study specifically aims to identify the main requirements, problems and key success factors with regards to these approaches. Integrating these approaches to the development process requires a deep analysis of the current development process, seeking the current problems and strenghts. Adopting both continuous deployment and continuous experimentaton also requires understanding the requirements of continuous deployment and continuous experimentation. 

Existing documented applications of continuous experimentation are primarily executed in the B2C domain, often with a SaaS product. Examples are the Microsoft EXP platform \cite{ep} and Etsy \cite{}. The focus of this study is in the B2B domain, with an application that is not used as SaaS. As the development process greatly varies in other teams inside the company, the focus is on a single team to narrow the scope.

An interview is used to analyze and identify the pain points continuous deployment and continuous experimentation encounter in the B2B domain. After the interview, results are analyzed and addressed... TODO: continue

\subsection{Case} %what is studied?
Kitchenham et al. (Kitchenham et al., 2002) state that the experimental context needs the three elements: background information, discussion of research hypotheses, and information about related research. The two former will be discussed here, and the latter in the section "Frame of reference".

The company in question is Steeri Oy, which is a medium-sized company specializing in managing, analyzing and improving the usage of customer data. In this research, the unit under the study is the Development & Integration team, which is split into two sub-teams: Dialog and CDM. 

The Dialog team focuses on developing a multiple-channel online marketing automation, iSteer Dialog. It is a software product designed to allow effective marketing on multiple channels, such as e-mail and websites, and to automate repetitive tasks. The product can be integrated to existing CRM solutions, and the data stored in CRM can then be effectively used for marketing purposes. The software is configured and integrated to the customer environment as project work. This deployment doesn't require additional code as per customer, but only different configuration files. 

The CDM team focuses on building a Master Data Management (cite) solution, which integrates the customers data sources such as CRM, ERP and billing system to create a single point of reference. The product also manages the data by removing duplicate records, matching same records and cleaning and validating the data with the help of external data such as the resident registration database. The product is deployed manually to a customer, and certain custom specific configurations and rules have to be implemented in the code. 

The development process of the team is elaborated in detail in the chapter "State of the practice". 

The unit of analysis is the development process of the team. The whole development process consists of the development framework used, but also of the interaction with customers, tools used in the current development process and the roles of individuals in the process. The unit of analysis is studied by focusing on interviewing individual members at different positions in the organisation. The purpose of the interview is to identify the pain points in the development process regarding continuous deployment and continuous experimentation. 

TODO: describe organisation structure %: https://docs.google.com/a/steeri.fi/spreadsheet/ccc?key=0Ai02aScOCplAdG9zQURicnlkM0ptTXhqbHN5ZE04X0E&usp=drive_web#gid=0

The organisation of Steeri Oy is of a divisional type, with each business area forming independent teams based on the products and projects. The sub-teams under study have a common team leader, but different product owners and middle management. 

Continuous deployment and continuous experimentation haven't been previously used by the case company.  

In the beginning of the study, feedback was only collected in the form of bug reports from the customers. The bugs were then prioritized according to the importance, and added into the Trello workflow. 

Under analysis is also the company's ways to interact with the customer.

\subsection{Theory} %frame of reference

This case study builds on existing research on both continuous deployment and continuous experimentation. The chapter State of the Art 

TODO: open this chapter

Based on the existing research in Continuous Experimentation and Continuous Deployment:

Crook et al: Seven pitfalls to avoid when running controlled experiments on the web

Eric Ries: The lean startup: How today's entrepreneurs use continuous innovation to create radically successful businesses

Kohavi et al: Practical guide to controlled experiments on the web: listen to your customers not to the hippo

Fagerholm et al: Building Blocks for Continuous Experimentation

Jan Bosch: Building products as innovation experiment systems

Olsson et al: Climbing the" Stairway to Heaven"--A Multiple-Case Study Exploring Barriers in the Transition from Agile Development towards Continuous Deployment of Software

Humble et al: The deployment production line

Humble et al: Continuous Delivery: Reliable Software Releases Through Build, Test, and Deployment Automation

Microsoft EXP platform

The researcher is a part of the development team of the company, but the viewpoint ...

\subsection{Research questions} %what to know? ##Research questions—what to know? these fulfill the objective##
%Literature review
\noindent \textbf{RQ 1: What is the Minimum Viable Process of continuous experimentation? How can the process be simplified without losing the benefits?}

\noindent Continuous experimentation process with multiple different roles is quite heavyweight, and not quickly adoptable. The purpose of this research question is to attempt to investigate whether only the core process of continuous experimentation can be adopted and used in practice. A way to do this is for example to avoid creating new roles only for the purpose of continuous experimentation. This way it is quick for companies to test whether the process suits their needs. This research question is answered based on literature review. \newline

%Literature review / Interview
\noindent \textbf{RQ 2: What are the differences in continuous experimentation and continuous delivery in B2B as compared to B2C?}

\noindent In B2B domain the connection with end users might not be established properly, and the customer feedback might only be received from certain key members. Running experiments on customer environments also requires a new deployment of the software product. TODO: question: contractual issues? The purpose of this research question is to identify the differences in the software development process and the product in B2B and B2C environments, and it is answered based on both literature review and interview. \newline

Question: selecting the correct OEC in b2b is harder. for example revenue. 
question: in B2C people develop their own product, but in B2B the feature ideas might come only from customer.

%Interview results have to be compared to literature review results
\noindent \textbf{RQ 3: Why would continuous experimentation benefit the case company? What are the problems and strengths of the current development process?}

\noindent To rationalize the decision to adopt continuous experimentation in a company, the actual benefits to the business have to be identified. This question is answered by comparing problems and benefits of literature review to the results of the interview. \newline

One idea is also to aid marketing by selling the MVPs to customers. This way we can pivot the product with customers, they can test it in practice and then decide whether to pay for the product or not.

%collect ideas from literature review and interview
\noindent \textbf{RQ 4: How to collect usage data and customer feedback in B2B domain, where user amounts can be very low?}

\noindent As compared to the B2C domain where the product is often deployed in cloud with a lot of users, B2B applications might only have a handful of users. This question is answered by collecting ideas from the literature review and interview results. \newline
-Legal issues
-Technical issues

%collect ideas from literature review and interview
\noindent \textbf{RQ 5: How should continuous experimentation be implemented as a development process?}

\noindent When the benefits and requirements are identified and the process is approved by a company, it has to be adopted in practice. This requires an answer to questions what, how, who and when. This question is answered by collecting ideas from the literature review and interview results. \newline
-Where do the feature ideas come from?
-What roles are required?

%How is the current interaction with the customer?
%	subquestion: What are the current roles and stakeholders?
%How should continuous experimentation guide the development process?
%	subquestion: Where do the development ideas come from? Customer, team, management?
%How to collect feedback in a B2B domain?
%	subquestion: Who should use the collected feedback?
%	subquestion: Who is responsible for collecting the feedback?
%How to collect feedback without a SaaS product?
 %   subquestion: Where should the data be stored?
  %  subquestion: How should the data be accessed?
%How to shorten the time between the idea and implementation?%
%	subquestion: What are the roles?
%How should continuous delivery be integrated in the development process?
%	subquestion: How to keep the product in a stage where it can be released at all times?
%What tools are necessary for continuous deployment?
%What tools are necessary for continuous experimentation?
%If an impact is done right now, when will the effects be visible?
%The whole pipe between the idea and implementation isn't yet completely perceived. Some parts are visible, but the entirety is still unclear.
%How do we validate whether a feature is succesful or not? 

\subsection{Methods} %how to collect data? TODO: what, how, why?
The primary source of information in this research are semi-structured interviews performed within the Development & Integration team and its management. TODO: business people? The interview consists of pre-defined themes as follows: (1) current development process, (2) current deployment process, (3) current interaction with customers, (4) problems and strengths in the current development process, (5) software product, (6) future ways with continuous deployment and continuous experimentation. Data triangulation will be implemented by interviewing multiple individuals. Methodological triangulation will be implemented by collecting documentary data regarding the development process. 	

%miksi tutkimuskysymyksiin voidaan vastata haastattelututkimuksella?
The interview was chosen as a data collection method because of the nature of the research questions. Since the study focuses on applying two development methods to the development process of a team, individual perceptions of members are required. As the case study doesn't include a technical implementation, quantitative measurements to properly measure the effects before and after implementation isn't an option. The research questions cannot be properly supported with quantitative data. There is also a uncertainty about how much information the interviewees are able to provide, and thus the questions are mostly open-ended. The nature of interviewees opinions on the research questions are also not known in advance, and quantifying it isn't simple. 

%miksi haastattelukysymykset vastaavat tutkimuskysymyksiin?
In order to answer the research questions, information regarding the development process, customer interaction and feedback, deployment process and technical product details are required. The interview is divided into themes to address these aspects. The interview questions address, among other things, the specific situations and action sequences of the interview rather than general opinions. 

\subsubsection{Data collection}
The interview has a standardized set of open-ended questions TODO: validate. Leading questions are avoided on purpose, and different probing techniques such as "What?"-questions are used.    
Interviews were performed in the native language of the interviewee if possible, otherwise in English.

%miksi olen valinnut semi-structured interview:n
The interviews were performed once with every subject. Semi-structured interview with open questions allow deep exploration of studied objects \cite{runeson2009guidelines}. The interview begins with a set of background questions, used in coding the interview data per subject. After the introductory questions, the main interview questions make up most of the interview. The interview session is structured based on areas under study rather than based on a specific model. The interviews are recorded in audio format, and then transcribed into text.   

%miksi valitsin nämä haastateltavat
Interview data is primarily sought from the developers of the development teams and the managers of the team. As the focus of the thesis is on the development process of a single team split into two sub-teams, all participants of the team and its management team were interviewed. 

Process data is sought from the process documents made by the team. Quantitative data, such as the Trello ticket flow time, is sought from Trello. Data regarding the development process is also collected from the internal documents.

\subsubsection{Data analysis} %http://en.wikipedia.org/wiki/Thematic_analysis#Phases_of_Thematic_Analysis
In this case study the data analysis is performed with tabulation \cite{runeson2009guidelines}, where coded data is arranged into tables to get an overview of the data. The data is organized by ..TODO.

The data is analysed based on template analysis, which is a way of thematically analysing qualitative data \cite{king1998template}. *-

%minkä/miksi olen valinnut tietyn tavan analysoida ja koostaa vastauksista tulokset/johtopäätöksiä
Template analysis was chosen as an analysis approach because it organises and analyses the data according to themes. It is also particularly effective when comparing the perspectives of different participant groups \cite{king2004using}. Since the thesis focuses on multiple themes and the interview on multiple groups, template analysis was seen as a suitable approach.   

%Template TODO: http://www.hud.ac.uk/hhs/research/template-analysis/what-is-template-analysis/ 

TODO: Analysis is done \cite{runeson2009guidelines}
Coding
Interview results are added to spreadsheet, with the participants grouped based on their teams. TODO: find analysis methods

"One example of a useful technique for analysis is tabulation, where the coded data is arranged in tables, which makes it possible to get an overview of the data. The data can, for example be organized in a table where the rows represent codes of interest and the columns represent interview subjects." \cite{runeson2009guidelines} TODO: Tabulationia käytetään.

 -roles (devs, business, PO's)

%If developers and business people agree, the company is heading to right direction TODO: seek quote

\subsection{Limitations}

\subsection{Interview questions}

\subsubsection{Background}

\begin{center}
    \begin{tabular}{ | l | l | l | p{5cm} |} 
    \hline
    ID & Question & Reason & Notes \\ \hline
    1 & Name of the interviewee & Background & - \\ \hline
    2 & Team of the interviewee & Background & - \\ \hline
    3 & Position of the interviewee & Background & - \\ \hline
    4 & Years in the company & Background & - \\ \hline
    5 & Years of experience in the industry & Background & - \\ \hline
    6 & What is the software product you're working with? & Background &  \\ \hline
    \hline
    \end{tabular}
\end{center}

\subsubsection{Current development process}

\begin{center}
    \begin{tabular}{ | l | l | l | p{5cm} |}
    \hline
    ID & Question & Reason & Notes \\ \hline
    a & Describe your personal daily work routine & General & \\ \hline
    a & Describe a normal week with your team & General & \\ \hline
    a & What is the current development model in your team? & General & d \\ \hline
    a & How has the development model evolved during your stay in the company? & General & d \\ \hline
    a & Where do the development ideas come from? Are they mostly requirements from customers? & Continuous experimentation & d \\ \hline
    %a & Are the current development ideas based on evidence or guesswork? & Continuous experimentation & d \\ \hline
    \hline
    \end{tabular}
\end{center}

\subsubsection{Current deployment process}

\begin{center}
    \begin{tabular}{ | l | l | l | p{5cm} |}
    \hline
    ID & Question & Reason & Notes \\ \hline
    a & What is the current deployment process like? & Continuous deployment & Deployment process \\ \hline
    a & Who decides when to deploy? & Continuous deployment & Deployment process \\ \hline %TODO: how is it decided?
    a & Who decides what to deploy? & Continuous deployment & Deployment process \\ \hline %TODO: how is it decided?
    a & How often is new version released ? & Continuous deployment & Deployment process \\ \hline
    a & How often are the new versions deployed to customer?? & Continuous deployment & Deployment process \\ \hline
    a & How are the deployment dates chosen? & Continuous deployment & Deployment process \\ \hline

    a & Which parts of the deployment process are manual? & Continuous deployment & Technical \\ \hline
    a & Which parts of the deployment process are hard to measure automatically? & Continuous deployment & Technical \\ \hline

    a & Is the customer involved in the deployment process? & Continuous deployment & Customer involvement \\ \hline
    a & Does the customer have to do something when a version is deployed? & Continuous deployment & Customer involvement \\ \hline

    a & What are the strenghts in the current deployment process? & Continuous deployment & d \\ \hline
    a & What are the problems in the current deployment process? & Continuous deployment & d \\ \hline
    \hline
    \end{tabular}
\end{center}

\subsubsection{Current interaction with the customer}

\begin{center}
%\centerline{
    \begin{tabular}{ | l | l | l | p{5cm} |}
    \hline
    ID & Question & Reason & Notes \\ \hline
    a & Who is responsible for interacting with the customer? & General & d \\ \hline
    a & From your point of view, what are the challenges with the customer interaction? & General & d \\ \hline
    a & From your point of view, what are the strengths with the customer interaction? & General & d \\ \hline
    a & From your point of view, how could the interaction with the customer be improved? & General & d \\ \hline
	a & Is it common for customers requirements to change? & General &  \\ \hline
    a & Is the development team aware of the customers present requirements? & General &  \\ \hline

	a & How is feedback collected from the customer? & Continuous experimentation & RQ 4: Data collection \\ \hline
	a & What are the B2B specific challenges in feedback collection? & Continuous experimentation & RQ 4: Data collection \\ \hline
	a & From your point of view, how could the feedback collection be improved? & Continuous experimentation & RQ 4: Data collection \\ \hline
	a & How is the customer feedback used? & Continuous experimentation & Data usage \\ \hline	
	a & From your point of view, how could the feedback usage be improved? & Continuous experimentation & Data usage \\ \hline

    \hline
    \end{tabular}
%    }
\end{center}

\subsubsection{Software product}

\begin{center}
    \begin{tabular}{ | l | l | l | p{5cm} |}
    \hline
    ID & Question & Reason & Notes \\ \hline
    a & How many end-users does the product have? & General &  \\ \hline
    a & How is usage data collected? & Continuous experimentation & RQ 4: Data collection \\ \hline
    a & How could usage data collection be improved? & Continuous experimentation & RQ 4: Data collection \\ \hline

    a & What technical challenges would real-time deployment have? & Continuous deployment & RQ 2 \\ \hline
    a & What technical challenges would plugged-in data collection instruments have? & Continuous experimentation & RQ 4: Data collection \\ \hline
    a & If data were to be collected in customer environment, what challenges would be faced storing it? & Continuous experimentation & RQ 4: Data storage \\ \hline
    \hline
    \end{tabular}
\end{center}

\subsubsection{Problems and strenghts in the current development process}

\begin{center}
    \begin{tabular}{ | l | l | l | p{5cm} |}
    \hline
    ID & Question & Reason & Notes \\ \hline
	a & What are the strenghts in the current development process? & General & RQ 3 \\ \hline
    a & What are the problems in the current development process? & General & RQ 3 \\ \hline
    \hline
    \end{tabular}
\end{center}

\subsubsection{Future ways with continuous deployment and continuous experimentation}

\begin{center}
    \begin{tabular}{ | l | l | l | p{5cm} |}
    \hline
    ID & Question & Reason & Notes \\ \hline
    a & Could your product be instrumented with a data collection service? If not, why? & Continuous experimentation & RQ 4: Data collection \\ \hline
    a & In your product, could experiments be quickly deployed to the customer environment? & Continuous experimentation & d \\ \hline
    a & In your product, could the development process be guided by A/B testing? & Continuous experimentation & d \\ \hline
    a & Does your team have a data analyst? & Continuous experimentation & d \\ \hline
    \hline
    \end{tabular}
\end{center}

\section{Research results}

\section{Analysis}

 (1) current development process, (2) current deployment process, (3) current interaction with customers, (4) problems and strengths in the current development process, (5) software product, (6) future ways with continuous deployment and continuous experimentation.

\subsection{Current development process}

\subsection{Current deployment process}

\subsection{Current interaction with the customer}

\subsection{Problems and strenghts in the current development process}

\subsection{Software product}

\subsection{Future ways with continuous deployment and continuous experimentation}

\textbf{RQ 1: What is the Minimum Viable Process of continuous experimentation? How can the process be simplified without losing the benefits?}
Based on the literature review

The interview

\textbf{RQ 2: What are the differences in continuous experimentation and continuous delivery in B2B as compared to B2C?}

The literature review revealed

\textbf{RQ 3: Why would continuous experimentation benefit the case company? What are the problems and strengths of the current development process?}


\textbf{RQ 4: How to collect usage data and customer feedback in B2B domain, where user amounts can be very low?}
\textbf{RQ 5: How should continuous experimentation be implemented as a development process?}


The simplest experiment cycle:
1.oec
2.
3.impl
4.analysis
5.steer

\section{Conclusions}

\newpage

% --- References ---
%
% bibtex is used to generate the bibliography. The babplain style
% will generate numeric references (e.g. [1]) appropriate for theoretical
% computer science. If you need alphanumeric references (e.g [Tur90]), use
%
% \bibliographystyle{babalpha-lf}
%
% instead.


\bibliographystyle{babplain-lf}
\bibliography{gradu}


% --- Appendices ---

% uncomment the following

% \newpage
% \appendix
% 
% \section{Example appendix}

\end{document}
