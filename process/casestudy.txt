CASE STUDY PLAN:

Objective—what to achieve?

The objective of the study may be, for example, exploratory, descriptive, explanatory, or
improving. The objective is naturally more generally formulated and less precise than in
fixed research designs. The objective is initially more like a focus point which evolves
during the study. The research questions state what is needed to know in order to fulfill the
objective of the study. Similar to the objective, the research questions evolve during the
study and are narrowed to specific research questions during the study iterations

& The case—what is studied?

The case may in general be virtually anything which is a “contemporary phenomenon in
its real-life context” (Yin 2003). In software engineering, the case may be a software
development project, which is the most straightforward choice. 

& Theory—frame of reference

Defining the frame of reference of the study makes the
context of the case study research clear, and helps both those conducting the research and
those reviewing the results of it.

& Research questions—what to know?


& Methods—how to collect data?

The principal decisions on methods for data collection are defined at design time for the
case study, although detailed decisions on data collection procedures are taken later.
Lethbridge et al. (2005) define three categories of methods: direct (e.g. interviews), indirect
(e.g. tool instrumentation) and independent (e.g. documentation analysis).

& Selection strategy—where to seek data?


CASE STUDY CHECkLIST

1. What is the case and its units of analysis?
2. Are clear objectives, preliminary research questions, hypotheses (if any) defined in advance?
3. Is the theoretical basis—relation to existing literature or other cases—defined?
4. Are the authors’ intentions with the research made clear?
5. Is the case adequately defined (size, domain, process, subjects…)?
6. Is a cause–effect relation under study? If yes, is it possible to distinguish the cause from other factors using
the proposed design?
7. Does the design involve data from multiple sources (data triangulation), using multiple methods (method
triangulation)?
8. Is there a rationale behind the selection of subjects, roles, artifacts, viewpoints, etc.?
9. Is the specified case relevant to validly address the research questions (construct validity)?
10. Is the integrity of individuals/organizations taken into account?


REST

1. Case study design: objectives are defined and 
the case study is planned. 
2. Preparation for data collection: procedures and 
protocols for data collection are defined. 
3. Collecting evidence: execution with data 
collection on the studied case. 
4. Analysis of collected data 
5. Reporting 

What is the object of study? 
2. Is a clear purpose/objective/research question 
/hypothesis/proposition defined upfront? 
3. Is the theoretical basis - relation to existing literature 
and other cases - defined? 
4. Are the authors’ intentions with the research made 
clear? 
5. Is the case adequately defined (size, domain, 
process…)? 
6. Is a cause-effect relation under study? If yes, is the 
cause distinguished from other factors? 
7. Will data be collected from multiple sources? Using 
multiple methods? 
8. Is there a rationale behind the selection of roles, 
artefacts, viewpoints, etc.? 
9. Are the case study settings relevant to validly address 
for the research question? 
10. Is the integrity of individuals/organizations taken into 
account? 
Preparation for Data Collection 
11. Is a protocol for data collection and analysis derived 
(what, why, how)? 
12. Are multiple data sources and collection methods 
planned? 
13. For quantitative data, are the measurements well 
defined? 
14. Are the planned methods and measurements sufficient 
to fulfil the objective of the study? 
15. Is the study design approved by a review board, and has 
informed consent obtained from individuals and 
organizations? 
Collecting Evidence 
16. Are data collected according to the protocol? 
17. Is the observed phenomenon correctly implemented 
(e.g. to what extent is a design method under study 
actually used)? 
18. Are data recorded to enable further analysis? 
19. Are sensitive results identified (for individuals, 
organization or project)? 
20. Are the data collection procedures well traceable? 
21. Do the collected data provide ability to address the 
research question? 
Analysis of Collected Data 
22. Is the analysis methodology defined, including roles and 
review procedures? 
23. Is a chain of evidence shown with traceable inferences 
from data to research questions and existing theory? 
24. Are alternative perspectives and explanations used in 
the analysis? 
25. Is a cause-effect relation under study? If yes, is the 
cause distinguished from other factors? 
26. Are there clear conclusions from the analysis, including 
recommendations for practice/further research? 
27. Are threats to validity addressed in a systematic way? 
 
 
 
Reporting 
28. Are the case and its context adequately reported? 
29. Are the research questions and corresponding answers 
reported? 
30. Are related theory, hypotheses and propositions clearly 
reported? 
31. Are the data collection procedures presented, with 
relevant motivation? 
32. Are sufficient raw data presented? 
33. Are the analysis procedures clearly reported. 
34. Are threats to validity analyses reported? 
35. Are ethical issues reported openly (personal intentions, 
integrity issues) 
36. Does the report contain conclusions, implications for 
practice and future research? 
37. Does the report give a realistic and credible impression? 
38. Is the report suitable for its audience, easy to read and 
well structured? 
 
 
Appendix B. Reviewer’s Checklist1
 
1. Are the research questions, objects of study and case 
study context well defined? 1, 2, 5, 28, 29 
2. Is it motivated that the case is suitable to address the 
research questions? 8, 9, 14 
3. Are the hypotheses and propositions clear and relevant? 
2, 30 
4. Are the data collection procedures sufficient for the 
purpose (data sources, collection, storage, validation)? 
11, 13, 16, 18, 21, 32 
5. Are sufficient raw data presented to provide 
understanding of the case? 31 
6. Are the analysis procedures sufficient for the purpose 
(repeatable, transparent)? 22, 33 
7. Is the case study based on theory and linked to existing 
literature? 3 
8. Is a clear chain of evidence established from 
observations to conclusions? 6, 17, 20, 23, 25 
9. Are threats to validity analyses addressed in a 
systematic way? 27, 34, 37 
10. Are different views taken on the case (multiple 
collection and analysis methods, multiple authors)? 7, 
12, 22, 24 
11. Are ethical issues addressed properly (personal 
intentions, integrity issues, consent, review board 
approval)? 4, 10, 15, 19, 35 
12. Are conclusions, implications for practice and future 
research, reported suitably for its audience? 26, 29, 36,